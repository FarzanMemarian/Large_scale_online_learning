{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Farzan Memarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA GENERATION\n",
    "\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import random\n",
    "import time\n",
    "from pdb import set_trace\n",
    "\n",
    "Nexam = 10**5\n",
    "Ndim = 20\n",
    "Nperm = 30\n",
    "x1 = np.random.multivariate_normal(mean= np.ones(Ndim), cov =  np.identity(Ndim),size = Nexam)\n",
    "y1 = np.ones(Nexam)\n",
    "x2 = np.random.multivariate_normal(mean= -np.ones(Ndim), cov =  np.identity(Ndim),size = Nexam)\n",
    "y2 = -np.ones(Nexam)\n",
    "\n",
    "X = np.concatenate((x1,x2),axis=0)\n",
    "y = np.concatenate((y1,y2))\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_tr_orig, X_test_orig, y_tr_orig, y_test_orig = model_selection.train_test_split(X,y,test_size=0.5)\n",
    "\n",
    "# reshaping y\n",
    "y_tr_orig = y_tr_orig.reshape((len(y_tr_orig),1))\n",
    "y_test_orig = y_test_orig.reshape((len(y_test_orig),1))\n",
    "\n",
    "perms = [] # array storing different premutatins of X, Y\n",
    "for _ in range(Nperm):\n",
    "    inx = np.random.permutation(Nexam)\n",
    "    X_perm = X_tr_orig[inx]\n",
    "    y_perm = y_tr_orig[inx]\n",
    "    perms.append([X_perm,y_perm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Batch newton algorithm with the Gauss-Newton approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "from numpy import outer, matmul, inner\n",
    "from numpy.linalg import inv, norm\n",
    "from scipy.sparse import diags\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def func(X, theta):\n",
    "    return  1.71 * np.tanh(0.66 * matmul(X, theta))\n",
    "\n",
    "def f_prime(X, theta):\n",
    "    return  1.71 * 0.66 *  (1 -  np.tanh(0.66 * matmul(X, theta)) )**2\n",
    "\n",
    "def gradient_loss(f, f_prime, y, X):\n",
    "    N = len(y)\n",
    "    g = np.zeros((Ndim,))\n",
    "    for i in range(N):\n",
    "        nabla_f_theta = f_prime[i] * X[i,:]\n",
    "        g += 0.5 * 2 * (f[i] - 1.5*y[i]) * nabla_f_theta\n",
    "    return g.reshape((Ndim,1))\n",
    "\n",
    "def hessian(f_prime, X):\n",
    "    h = np.zeros((Ndim,Ndim))\n",
    "    N,_ = np.shape(X)\n",
    "    for i in range(N):\n",
    "        h += f_prime[i]**2 * np.outer(X[i,:],X[i,:])\n",
    "    return h\n",
    "\n",
    "def batch_newton_step(X, y, theta):\n",
    "\n",
    "    f = func(X, theta)\n",
    "#     print (\"mse f, y: {}\".format(mean_squared_error(f,y)) )\n",
    "    f_p = f_prime(X, theta)\n",
    "    g = gradient_loss(f, f_p, y, X)\n",
    "    h = hessian(f_p, X)\n",
    "    h_inv = inv(h)\n",
    "    d_theta = -matmul(h_inv, g)\n",
    "    return d_theta\n",
    "\n",
    "def batch_newton_iter(X, y, theta_init, thresh):\n",
    "    theta = theta_init\n",
    "    keep_iter = True\n",
    "    counter = 0\n",
    "    while keep_iter:\n",
    "#         counter += 1\n",
    "#         if counter % 10 == 0:\n",
    "#             print (\"iter:\", counter)\n",
    "#             print (\"error\", norm(d_theta))\n",
    "#             print (\"threshold\", thresh)\n",
    "        d_theta = batch_newton_step(X, y, theta)\n",
    "\n",
    "        if norm(d_theta) > thresh:\n",
    "            theta += d_theta\n",
    "        else:\n",
    "            keep_iter = False\n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR 100 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n",
      "RUNNING FOR 1000 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n"
     ]
    }
   ],
   "source": [
    "# TRAINING BATCH NEWTON ALGORITHM\n",
    "\n",
    "# Nsizes = 5\n",
    "# n_ex_float = np.floor(np.logspace(3.0, 5.0, num=Nsizes))\n",
    "# n_ex = [int(item) for item in n_ex_float]\n",
    "n_ex = [100,1000, 5000]\n",
    "\n",
    "theta_store_all_N = []\n",
    "time_storage_N = []\n",
    "for N in n_ex:\n",
    "    print (\"RUNNING FOR {} EXAMPLES\".format(N))\n",
    "    start_time = time.time()\n",
    "    theta_store = []\n",
    "    thresh = 0.01/N\n",
    "    perm_counter = 0\n",
    "    for X_all,y_all in perms:\n",
    "        X = X_all[:N,:]\n",
    "        y = y_all[:N]\n",
    "        perm_counter += 1\n",
    "        if perm_counter % 5 == 0:\n",
    "            print (\"perm counter: \", perm_counter)\n",
    "        theta_init = np.random.uniform(-0.5, 0.5, size=Ndim).reshape((Ndim,1))\n",
    "        theta = batch_newton_iter(X, y, theta_init, thresh)\n",
    "        theta_store.append(theta)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_storage_N.append(elapsed_time)\n",
    "    theta_store_all_N.append(theta_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THETAS AND TIMES FOR NEWTON\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('theta_store_all_N.txt', 'wb') as fp:\n",
    "    pickle.dump(theta_store_all_N, fp)\n",
    "    \n",
    "with open('time_storage_N.txt', 'wb') as fb:\n",
    "    pickle.dump(time_storage_N, fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eda2c17b6541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtheta_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtheta_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_newton_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'theta_star'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7aea97611bea>\u001b[0m in \u001b[0;36mbatch_newton_iter\u001b[0;34m(X, y, theta_init, thresh)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#             print (\"error\", norm(d_theta))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m#             print (\"threshold\", thresh)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0md_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_newton_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_theta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7aea97611bea>\u001b[0m in \u001b[0;36mbatch_newton_step\u001b[0;34m(X, y, theta)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mf_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mh_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0md_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7aea97611bea>\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(f_prime, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf_prime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # FIND THETA* ON TEST SET USING NEWTON METHOD\n",
    "        \n",
    "# N = len(y_test_orig)\n",
    "\n",
    "# thresh = 0.01/N\n",
    "\n",
    "# X = X_test_orig[:N,:]\n",
    "# y = y_test_orig[:N]\n",
    "\n",
    "# theta_init = np.random.uniform(-0.5, 0.5, size=Ndim).reshape((Ndim,1))\n",
    "# start_time = time.time()\n",
    "# theta_star = batch_newton_iter(X, y, theta_init, thresh)\n",
    "# np.save('theta_star', theta_star)\n",
    "# end_time = time.time()\n",
    "# elapsed_time_test = end_time - start_time\n",
    "# print (\"elapsed time for test set: {}\".format(elapsed_time_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read THETA*\n",
    "theta_star = np.load(\"theta_star.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B)  Implement the Online-Kalman algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def online_kalman(X,y,N):\n",
    "    # Online Kalman Filter \n",
    "\n",
    "    phi = np.identity(Ndim) # Initializing as identity \n",
    "    theta = np.random.uniform(-0.5,0.5,size=Ndim) # Parameter vector has dimension Ndim \n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    f = func(X, theta)\n",
    "    df =  f_prime(X, theta)\n",
    "    \n",
    "    for j in range(N):\n",
    "        tau = max(20,j-40)\n",
    "\n",
    "        phi=np.linalg.inv((1-2/tau)*np.linalg.inv(phi)+ (2/tau)*(df[j]*df[j])*(np.outer(X[j,:],X[j,:])))\n",
    "\n",
    "        dL=X[j,:]*(-2*df[j]*(1.5*y[j]-f[j]))\n",
    "\n",
    "        theta = theta - (1/tau)*phi.dot(dL)\n",
    "        \n",
    "    time_o_run= (time.time() - start_time)\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time_o_run))\n",
    "    \n",
    "    return (theta,time_o_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR 5000 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n",
      "RUNNING FOR 10000 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n"
     ]
    }
   ],
   "source": [
    "# TRAINING ONLINE KALMAN ALGORITHM\n",
    "\n",
    "Nsizes = 5\n",
    "n_ex_float = np.floor(np.logspace(3.0, 5.0, num=Nsizes))\n",
    "n_ex = [int(item) for item in n_ex_float]\n",
    "# n_ex = [5000,10000]\n",
    "\n",
    "theta_store_all_K = []\n",
    "time_storage_K = []\n",
    "for N in n_ex:\n",
    "    print (\"RUNNING FOR {} EXAMPLES\".format(N))\n",
    "    \n",
    "    theta_store = []\n",
    "    thresh = 0.01/N\n",
    "    perm_counter = 0\n",
    "    start_time = time.time()\n",
    "    for X_all,y_all in perms:\n",
    "        X = X_all[:N,:]\n",
    "        y = y_all[:N]\n",
    "        perm_counter += 1\n",
    "        if perm_counter % 5 == 0:\n",
    "            print (\"perm counter: \", perm_counter)\n",
    "        theta, _ = online_kalman(X,y,N)\n",
    "        theta_store.append(theta)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_storage_K.append(elapsed_time)\n",
    "    theta_store_all_K.append(theta_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THETAS AND TIMES FOR KALMAN\n",
    "import pickle\n",
    "    \n",
    "with open('theta_store_all_K.plk', 'wb') as fp:\n",
    "    pickle.dump(theta_store_all_K, fp)\n",
    "    \n",
    "with open('time_storage_K.plk', 'wb') as fb:\n",
    "    pickle.dump(time_storage_K, fb)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) evaluations and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse for different examples:  [[0.04227653964343106, 100], [0.023624510109318386, 1000]]\n",
      "mse star:  0.0222693284277\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION OF METHODS ON TEST SET\n",
    "\n",
    "# find mse error on test data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "store_mse = []\n",
    "X = X_test_orig\n",
    "y = y_test_orig\n",
    "for i, N in enumerate(n_ex):\n",
    "    mse = 0\n",
    "    for j in range(Nperm):\n",
    "        theta = theta_store_all_N[i][j]\n",
    "        f = func(X, theta)\n",
    "        mse += mean_squared_error(f,1.5*y)/Nperm\n",
    "    f_star = func(X, theta_star)\n",
    "    mse_star = mean_squared_error(f_star,1.5*y)\n",
    "    store_mse.append([mse,N])\n",
    "print (\"mse for different examples: \", store_mse)\n",
    "print (\"mse star: \", mse_star)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.91166250963\n",
      "-6.60381975126\n"
     ]
    }
   ],
   "source": [
    "print (np.log(0.04227653964343106  - 0.0222693284277))\n",
    "print (np.log(0.023624510109318386 - 0.0222693284277))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36222003368403394"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(theta_store_all_N[0][0] - theta_store_all_N[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0432198960423\n"
     ]
    }
   ],
   "source": [
    "print ( np.mean([norm(theta_store_all[1][i] - theta_star) for i in range(Nperm)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
