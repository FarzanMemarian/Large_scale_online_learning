{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Farzan Memarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA GENERATION\n",
    "\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import random\n",
    "import time\n",
    "from pdb import set_trace\n",
    "\n",
    "Nexam = 10**5\n",
    "Ndim = 20\n",
    "Nperm = 30\n",
    "x1 = np.random.multivariate_normal(mean= np.ones(Ndim), cov =  np.identity(Ndim),size = Nexam)\n",
    "y1 = np.ones(Nexam)\n",
    "x2 = np.random.multivariate_normal(mean= -np.ones(Ndim), cov =  np.identity(Ndim),size = Nexam)\n",
    "y2 = -np.ones(Nexam)\n",
    "\n",
    "X = np.concatenate((x1,x2),axis=0)\n",
    "y = np.concatenate((y1,y2))\n",
    "\n",
    "from sklearn import model_selection\n",
    "X_tr_orig, X_test_orig, y_tr_orig, y_test_orig = model_selection.train_test_split(X,y,test_size=0.5)\n",
    "\n",
    "# reshaping y\n",
    "y_tr_orig = y_tr_orig.reshape((len(y_tr_orig),1))\n",
    "y_test_orig = y_test_orig.reshape((len(y_test_orig),1))\n",
    "\n",
    "perms = [] # array storing different premutatins of X, Y\n",
    "for _ in range(Nperm):\n",
    "    inx = np.random.permutation(Nexam)\n",
    "    X_perm = X_tr_orig[inx]\n",
    "    y_perm = y_tr_orig[inx]\n",
    "    perms.append([X_perm,y_perm])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Batch newton algorithm with the Gauss-Newton approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "from numpy import outer, matmul, inner\n",
    "from numpy.linalg import inv, norm\n",
    "from scipy.sparse import diags\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def func(X, theta):\n",
    "    return  1.71 * np.tanh(0.66 * matmul(X, theta))\n",
    "\n",
    "def f_prime(X, theta):\n",
    "    return  1.71 * 0.66 *  (1 -  np.tanh(0.66 * matmul(X, theta)) )**2\n",
    "\n",
    "def gradient_loss(f, f_prime, y, X):\n",
    "    N = len(y)\n",
    "    g = np.zeros((Ndim,))\n",
    "    for i in range(N):\n",
    "        nabla_f_theta = f_prime[i] * X[i,:]\n",
    "        g += 0.5 * 2 * (f[i] - 1.5*y[i]) * nabla_f_theta\n",
    "    return g.reshape((Ndim,1))\n",
    "\n",
    "def hessian(f_prime, X):\n",
    "    h = np.zeros((Ndim,Ndim))\n",
    "    N,_ = np.shape(X)\n",
    "    for i in range(N):\n",
    "        h += f_prime[i]**2 * np.outer(X[i,:],X[i,:])\n",
    "    return h\n",
    "\n",
    "def batch_newton_step(X, y, theta):\n",
    "\n",
    "    f = func(X, theta)\n",
    "#     print (\"mse f, y: {}\".format(mean_squared_error(f,y)) )\n",
    "    f_p = f_prime(X, theta)\n",
    "    g = gradient_loss(f, f_p, y, X)\n",
    "    h = hessian(f_p, X)\n",
    "    h_inv = inv(h)\n",
    "    d_theta = -matmul(h_inv, g)\n",
    "    return d_theta\n",
    "\n",
    "def batch_newton_iter(X, y, theta_init, thresh):\n",
    "    theta = theta_init\n",
    "    keep_iter = True\n",
    "    counter = 0\n",
    "    while keep_iter:\n",
    "#         counter += 1\n",
    "#         if counter % 10 == 0:\n",
    "#             print (\"iter:\", counter)\n",
    "#             print (\"error\", norm(d_theta))\n",
    "#             print (\"threshold\", thresh)\n",
    "        d_theta = batch_newton_step(X, y, theta)\n",
    "\n",
    "        if norm(d_theta) > thresh:\n",
    "            theta += d_theta\n",
    "        else:\n",
    "            keep_iter = False\n",
    "    return theta\n",
    "\n",
    "def online_kalman(X,y,N):\n",
    "    # Online Kalman Filter \n",
    "\n",
    "    phi = np.identity(Ndim) # Initializing as identity \n",
    "    theta = np.random.uniform(-0.5,0.5,size=Ndim) # Parameter vector has dimension Ndim \n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    f = func(X, theta)\n",
    "    df =  f_prime(X, theta)\n",
    "    \n",
    "    for j in range(N):\n",
    "        tau = max(20,j-40)\n",
    "\n",
    "        phi=np.linalg.inv((1-2/tau)*np.linalg.inv(phi)+ (2/tau)*(df[j]*df[j])*(np.outer(X[j,:],X[j,:])))\n",
    "\n",
    "        dL=X[j,:]*(-2*df[j]*(1.5*y[j]-f[j]))\n",
    "\n",
    "        theta = theta - (1/tau)*phi.dot(dL)\n",
    "        \n",
    "    time_o_run= (time.time() - start_time)\n",
    "\n",
    "#     print(\"--- %s seconds ---\" % (time_o_run))\n",
    "    \n",
    "    return (theta,time_o_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR 100 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n",
      "RUNNING FOR 5000 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n"
     ]
    }
   ],
   "source": [
    "# TRAINING ONLINE KALMAN ALGORITHM\n",
    "\n",
    "# Nsizes = 5\n",
    "# n_ex_float = np.floor(np.logspace(3.0, 5.0, num=Nsizes))\n",
    "# n_ex = [int(item) for item in n_ex_float]\n",
    "n_ex = [100,5000]\n",
    "\n",
    "theta_store_all_k = []\n",
    "time_storage_k = []\n",
    "for N in n_ex:\n",
    "    print (\"RUNNING FOR {} EXAMPLES\".format(N))\n",
    "    \n",
    "    theta_store = []\n",
    "    thresh = 0.01/N\n",
    "    perm_counter = 0\n",
    "    start_time = time.time()\n",
    "    for X_all,y_all in perms:\n",
    "        X = X_all[:N,:]\n",
    "        y = y_all[:N]\n",
    "        perm_counter += 1\n",
    "        if perm_counter % 5 == 0:\n",
    "            print (\"perm counter: \", perm_counter)\n",
    "        theta, _ = online_kalman(X,y,N)\n",
    "        theta_store.append(theta)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_storage_k.append(elapsed_time)\n",
    "    theta_store_all_k.append(theta_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time for test set: 1.4619536399841309\n"
     ]
    }
   ],
   "source": [
    "# FIND THETA* ON TEST SET\n",
    "        \n",
    "# N = len(y_test_orig) \n",
    "N = 1000\n",
    "thresh = 0.01/N\n",
    "\n",
    "X = X_test_orig[:N,:]\n",
    "y = y_test_orig[:N]\n",
    "\n",
    "theta_init = np.random.uniform(-0.5, 0.5, size=Ndim).reshape((Ndim,1))\n",
    "start_time = time.time()\n",
    "theta_star = batch_newton_iter(X, y, theta_init, thresh)\n",
    "np.save('theta_star', theta_star)\n",
    "end_time = time.time()\n",
    "elapsed_time_test = end_time - start_time\n",
    "print (\"elapsed time for test set: {}\".format(elapsed_time_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING FOR 1000 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n",
      "perm counter:  30\n",
      "RUNNING FOR 3162 EXAMPLES\n",
      "perm counter:  5\n",
      "perm counter:  10\n",
      "perm counter:  15\n",
      "perm counter:  20\n",
      "perm counter:  25\n"
     ]
    }
   ],
   "source": [
    "# TRAINING BATCH NEWTON ALGORITHM\n",
    "\n",
    "Nsizes = 5\n",
    "n_ex_float = np.floor(np.logspace(3.0, 5.0, num=Nsizes))\n",
    "n_ex = [int(item) for item in n_ex_float]\n",
    "# n_ex = [1000,5000]\n",
    "\n",
    "theta_store_all = []\n",
    "time_storage = []\n",
    "for N in n_ex:\n",
    "    print (\"RUNNING FOR {} EXAMPLES\".format(N))\n",
    "    start_time = time.time()\n",
    "    theta_store = []\n",
    "    thresh = 0.01/N\n",
    "    perm_counter = 0\n",
    "    for X_all,y_all in perms:\n",
    "        X = X_all[:N,:]\n",
    "        y = y_all[:N]\n",
    "        perm_counter += 1\n",
    "        theta_init = np.random.uniform(-0.5, 0.5, size=Ndim).reshape((Ndim,1))\n",
    "        theta = batch_newton_iter(X, y, theta_init, thresh)\n",
    "        if perm_counter % 5 == 0:\n",
    "            print (\"perm counter: \", perm_counter)\n",
    "        theta_store.append(theta)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    time_storage.append(elapsed_time)\n",
    "    theta_store_all.append(theta_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THETAS AND TIMES\n",
    "import pickle\n",
    "\n",
    "with open('thetas_all', 'wb') as fp:\n",
    "    pickle.dump(theta_store2, fp)\n",
    "    \n",
    "with open('times', 'wb') as fb:\n",
    "    pickle.dump(time_storage, fb)\n",
    "    \n",
    "    \n",
    "# with open ('thetas2', 'rb') as fp:\n",
    "#     itemlist = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse for different examples:  [[0.79345685202992511, 100], [0.65260936987271645, 5000]]\n",
      "mse star:  0.236658949751\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION OF NEWTON METHOD ON TEST SET\n",
    "\n",
    "# find mse error on test data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "store_mse = []\n",
    "X = X_test_orig\n",
    "y = y_test_orig\n",
    "for i, N in enumerate(n_ex):\n",
    "    mse = 0\n",
    "    for j in range(Nperm):\n",
    "        theta = theta_store_all_k[i][j]\n",
    "        f = func(X, theta)\n",
    "        mse += mean_squared_error(f,y)/Nperm\n",
    "    f_star = func(X, theta_star)\n",
    "    mse_star = mean_squared_error(f_star,y)\n",
    "    store_mse.append([mse,N])\n",
    "print (\"mse for different examples: \", store_mse)\n",
    "print (\"mse star: \", mse_star)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0988805899688\n"
     ]
    }
   ],
   "source": [
    "print (np.mean([norm(theta_store_all[0][i] - theta_star) for i in range(Nperm)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0432198960423\n"
     ]
    }
   ],
   "source": [
    "print ( np.mean([norm(theta_store_all[1][i] - theta_star) for i in range(Nperm)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
